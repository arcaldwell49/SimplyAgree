---
title: "Agreement & Tolerance Limits"
author: "Aaron R. Caldwell"
date: "Last Updated: `r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
bibliography: refs.bib
link-citations: true
vignette: >
  %\VignetteIndexEntry{Agreement & Tolerance Limits}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this vignette I will briefly demonstrate how `SimplyAgree` calculates agreement and tolerance limits. This vignette assumes the reader has some familiarity with "limits of agreement" (Bland-Altman limits) and is familiar with the concept of prediction intervals. Please read the references listed in this vignette *before* going further if you are not familiar with these concepts.

```{r}
library(SimplyAgree)
data(temps)
```

# Agree or Tolerate?

@francq2020tolerate pose this question in a paper published in *Statistics in Medicine*. Traditionally, those working in medicine or physiology have defaulted to calculating some form of "limits of agreement" that @bland1986 once recommended. The recommendation by @bland1986 was only an approximation, and that has undergone many modifications [@bland1999; @zou2011] to improve the accuracy of the agreement interval and their associated confidence intervals. Meanwhile, the field of industrial statistics has focused on calculating tolerance limits. There are R packages, such as the `tolerance` R package available on CRAN, that are entirely dedicated to calculating tolerance limits. It is important to note that tolerance is not limited to the normal distribution and can be applied to other distributions (please see the tolerance package for more details). However, in agreement studies typically seen in medicine, tolerance limits may be a more accurate way of determining whether two measurements adequately close to one another.

To quote @francq2020tolerate:

> In terms of terminology, tolerance means, in this context, that some difference between the methods is tolerated (the measurements are still comparable in practice). Furthermore, the tolerance interval is exact and therefore more appropriate than the agreement interval.

In this package, tolerance limits refer to the "tolerance" associated with the prediction interval for the difference between 2 measurements. The calculative approach (detailed much further below) involves calculated the prediction interval for the difference between two methods (i.e., an estimate of an interval in which a future observation will fall, with a certain probability, given what has already been observed) and then calculating the confidence in the interval (i.e., tolerance). Therefore, if we want a 95% prediction interval with 95% tolerance limits, we are calculating the interval in which 95% of future observations (prediction) with only a 5% probability (1-tolerance) the "true" prediction interval limits are greater/less than the upper/lower tolerance limits.

Personally, I find tolerance limits more attractive for 2 reasons: 1) the coverage of the prediction intervals and their tolerance limits is often better than confidence intervals for agreement limits, and 2) the interpretation of the tolerance limits is much clearer. For a greater discussion of this topic, please see the manuscript by @francq2020tolerate and their R package `BivRegBLS`.


# Tolerance

In `SimplyAgree` we utilize a generalized least square (GLS) to estimate the tolerance limits.
The function uses the `gls` function from the `nlme` R package to build the model.
This allows a *very* flexible approach for estimating prediction intervals and tolerance limits.

We can use the `tolerance_limits` function demonstrate the basic calculations.
In this example (below), we use the `temps` data set to measure the differences between esophageal and rectal temperatures between different times of day (`tod`) and controlling for the intra-subject correlation.

```{r}
tolerance_limit(
  data = temps,
  x = "trec_pre", # First measure
  y = "teso_pre", # Second measure
  id = "id", # Subject ID
  condition = "tod", # Identify condition that may affect differences
  cor_type = "sym" # Set correlation structure as Compound Symmetry
)
```


## Calculative Approach

Overall, the model is fit using the `gls` function, and I would suggest reading book by Pinheiro and Bates which details the function^[Pinheiro, J.C., and Bates, D.M. (2000) "Mixed-Effects Models in S and S-PLUS", Springer, esp. pp. 100, 461.]. This function is different than the linear, or linear mixed, models that are utilized in calculating limits of agreement because it accommodates correlated errors and/or unequal variances.

### Arguments Influencing the Model

Users of the this function have a number of options with the arguments provided in the `tolerance_limit` function. The only required arguments are `x`, `y`, and `data` which dictate the data frame, and the columns that contain the 2 measurements. The `id` argument, when specified, identifies the column that contains the subject identifier or some time of nesting within which the data should be correlated to some degree. The `time`, argument is utilized when the data come from a repeated measures or time series data, and indicates the order of the data points. The `condition` argument identifies some factor within a data frame that may effect the mean difference (and variance) of the differences between the 2 measurements. The `cor_type` argument can also be utilized to specific 1 of 3 possible correlation structure types. Lastly, savvy users can specify a particular variance or correlation structure using the `weights` and `correlation` arguments which directly alter the model being fit using `gls`.

### Prediction 

After the model is fit, the marginal means (EMM), and their associated standard errors (SEM), are calculated based on the `gls` fit model using `emmeans`. The standard error of prediction (SEP) for each EMM is then calculated using the SEM and residual standard error from the model (formula below).

$$
SEP = \sqrt{SEM^2 + S^2_{residual} }
$$

After the SEP is calculated, the prediction interval can be calculated with following:

$$
PI = EMM \pm t_{1-\alpha/2, df} \cdot SEP
$$

**NOTE**: the degrees of freedom (df) are calculated using Satterthwaite's approximation.

### Tolerance 

Tolerance limits are calculated either through the "Beta expectation" approximation detailed by @francq2020tolerate or through a parametric bootstrap method. 
The bootstrap methods re-samples from the model and after a certain number of replicates (default is 1999) calculates the bounds the prediction interval.
The bootstrap method is preferred for its accuracy and power, but is *extremely* slow which may involve computations lasting greater than 2 minutes.
The approximation is the default only because it is substantially quicker.

The approximate tolerance limits based on the work of @francq2020tolerate are calculated as the following:

$$
TI = EMM \pm z_{1-\alpha_1/2} \cdot SEP \cdot \sqrt{\frac{df}{\chi^2_{\alpha_2,df}}}
$$
**NOTE**: $\alpha_1$ refers to the alpha-level for the prediction interval (modified by the `pred_level` argument) whereas $alpha_2$ refers to the alpha-level for the tolerance limit (modified by the `tol_level` argument).

# Agreement

## Calculations for Simple Agreement

## Calculations for Replicate Agreement

## Calculations for Nested Agreement


# Simple Agreement

In the simplest scenario, a study may be conducted to compare one measure (e.g., `x`) and another (e.g., `y`). In this scenario each pair of observations (x and y) are *independent*; meaning that each pair represents one subject/participant.

The data for the two measurements are put into the `x` and `y` arguments. If there is a hypothesized limit of agreement then this can be set with the `delta` argument (this is optional). Next, the limit of agreement can be set with the `agree.level` and the confidence level ($1-\alpha$). Once those are set the analysis can be run. Please note, this package has pre-loaded data from the Zou 2013 paper. While data does not conform the assumptions of the test it can be used to test out many of the functions in this package. Since there isn't an *a priori* hypothesis I will not declare a `delta` argument, but I will estimate the 95% confidence intervals for 80% limits of agreement.

```{r}
a1 = agree_test(x = reps$x,
                y = reps$y,
                agree.level = .8)
```

We can then print the general results. These results include the general parameters of the analysis up top, then the results of the Shieh exact test for agreement (no conclusion is included due to the lack of a `delta` argument being set). Then the limits of agreement, with confidence limits, are included. Lastly, Lin's Concordance Correlation Coefficient, another measure of agreement, is also included.

```{r}
print(a1)
```

Next, we can use the generic `plot` function to produce visualizations of agreement. This includes the Bland-Altman plot (`type = 1`) and a line-of-identity plot (`type = 2`).

```{r, fig.width=6, fig.height=6}
plot(a1, type = 1)

plot(a1, type = 2) 
```


## Calculations in for Simple Agreement


### Limits of Agreement

The reported limits of agreement are derived from the work of @bland1986 and @bland1999.

**LoA**

$$
LoA = \bar d \pm z_{1-(1-agree)/2} \cdot S_d
$$
wherein $z_{1-(1-agree)/2}$ is the value of the normal distribution at the given agreement level (default is 95%), $\bar d$ is the mean of the differences, and $S_d$ is the standard deviations of the differences.

**Confidence Interval**

$$
LoA_{C.I.} = LoA \pm t_{1-\alpha/2,N-1} \cdot \sqrt{\left[\frac{1}{N}+\frac{(z_{1-\alpha/2})^{2}}{2 \cdot (N-1)} \right] \cdot S^2}
$$

wherein, $t$ is the critical t-value at the given sample size and confidence level (`conf.level`), $z$ is the value of the normal distribution at the given alpha level (`agree.level`), and $S^2$ is the variance of the difference scores. If `TOST` is set to TRUE then equation is altered slightly with the critical t ($t_{1-\alpha,N-1}$).

# Repeated Measures Agreement

In many cases there are multiple measurements taken within subjects when comparing two measurements tools. In some cases the true underlying value will not be expected to vary (i.e., replicates; `agree_reps`), or multiple measurements may be taken within an individual *and* these values are expected to vary (i.e., nested design; `agree_nest`).

The confidence limits on the limits of agreement are based on the "MOVER" method described in detail by @zou2011. However, both functions operate similarly to `agree_test`; the only difference being that the data has to be provided as a `data.frame` in R.

## `agree_reps`

This function is for cases where the underlying values do *not* vary within subjects. This can be considered cases where replicate measure may be taken. For example, a researcher may want to compare the performance of two ELISA assays where measurements are taken in duplicate/triplicate.

So, for this function you will have to provide the data frame object with the `data` argument and the names of the columns containing the first (`x` argument) and second (`y` argument) must then be provided. An additional column indicating the subject identifier (`id`) must also be provided. Again, if there is a hypothesized agreement limit then this could be provided with the `delta` argument.

```{r}
a2 = agree_reps(x = "x",
                y = "y",
                id = "id",
                data = reps,
                agree.level = .8)
```

The results can then be printed and plotted.

```{r}
print(a2)
```
```{r, fig.width=6, fig.height=6}
plot(a2)
```

## `agree_nest`

This function is for cases where the underlying values may vary within subjects. This can be considered cases where there are distinct pairs of data wherein data is collected in different times/conditions within each subject. An example would be measuring blood pressure on two different devices on many people at different time points/days.

The function works almost identically to `agree_reps` but the underlying calculations are different


```{r}
a3 = agree_nest(x = "x",
                y = "y",
                id = "id",
                data = reps,
                agree.level = .8)
```

The printed results (and plots) are very similar to `agree_reps`. However, the CCC result now has a warning because the calculation in this scenario may not be entirely appropriate given the nature of the data.

```{r}
print(a3)
```
```{r, fig.width=6, fig.height=6}
plot(a3)
```

## Calculations for `agree_reps` & `agree_nest`

All the calculations for the limits of agreement in these two functions can be found in the article by @zou2011.

## `agree_nest` LoA

**Step 1: Calculate Individual Subject Means and Variances**

$$
\bar x_i = \frac{1}{n_{xi}} \Sigma_{j=1}^{n_{xi}} x_{ij}
$$
$$
\bar y_i = \frac{1}{n_{yi}} \Sigma_{j=1}^{n_{yi}} y_{ij}
$$
$$
\bar d_i = \bar x_i - \bar y_i
$$

$$
\bar d = \Sigma_{i=1}^{n}\frac{d_i}{n} 
$$

$$
s_{xi}^2 = \Sigma_{j=1}^{n_{xi}} \frac{(x_{xj}- \bar x_i)^2}{n_{xi}-1}
$$

$$
s_{yi}^2 = \Sigma_{j=1}^{n_{yi}} \frac{(y_{ij}- \bar y_i)^2}{n_{yi}-1}
$$

$$
s_{\bar d}^2 = \Sigma_{j=1}^{n} \frac{(d_{i}- \bar d)^2}{n-1}
$$

**Step 2: Compute pooled estimates of within subject errors**

$$
s^2_{xw} = \Sigma_{i=1}^{n} [\frac{n_{xi} -1}{N_x -1} \cdot s^2_{xi}]
$$

$$
s^2_{yw} = \Sigma_{i=1}^{n} [\frac{n_{yi} -1}{N_y -1} \cdot s^2_{yi}]
$$

**Step 3: Compute Harmonic Means of Replicates**

$$
m_{xh} = \frac{n}{\Sigma_{i=1}^n \frac{1}{n_{xi}}}
$$

$$
m_{yh} = \frac{n}{\Sigma_{i=1}^n \frac{1}{n_{yi}}}
$$
**Step 4: Compute the variance of the differences**

$$
s^2_d = s^2_{\bar d} + (1+\frac{1}{m_{xh}}) \cdot s^2_{xw} + (1+\frac{1}{m_{yh}}) \cdot s^2_{yw}
$$
**Step 5: Compute MOVER Components**

$$
S_{11} = s_{\bar d}^2 \cdot (1 - \frac{n-1}{\chi^2_{(1-\alpha, n-1)}})
$$

$$
S_{12} = (1-\frac{1}{m_{xh}}) \cdot (1 - \frac{N_x-n}{\chi^2_{(1-\alpha, N_x-n)}}) \cdot s^2_{xw}
$$
$$
S_{13} = (1-\frac{1}{m_{yh}}) \cdot (1 - \frac{N_y-n}{\chi^2_{(1-\alpha, N_y-n)}}) \cdot s^2_{yw}
$$

$$
S_1 = \sqrt{S_{11}^2 +S_{12}^2 +S_{13}^2}
$$
$$
l = s_d^2 - S_1
$$

$$
u = s_d^2 + S_1
$$

$$
LME = \sqrt{\frac{z^2_{\alpha} \cdot s_d^2}{n} + z^2_{\beta/2} \cdot(\sqrt{u} - \sqrt{s^2_d})^2}
$$

$$
RME = \sqrt{\frac{z^2_{\alpha} \cdot s_d^2}{n} + z^2_{\beta/2} \cdot(\sqrt{l} - \sqrt{s^2_d})^2}
$$
### LoA

$$
LoA_{lower} = \bar d - z_{\beta/2} \cdot s_d
$$

$$
LoA_{upper} = \bar d + z_{\beta/2} \cdot s_d
$$

### Lower LoA CI

$$
Lower \space CI = LoA_{lower} - LME
$$


$$
Upper \space CI = LoA_{lower} + RME
$$

### Upper LoA CI

$$
Lower \space CI = LoA_{upper} - RME
$$


$$
Upper \space CI = LoA_{upper} + LME
$$

## `agree_reps` LoA

### LoA

**Step 1: Compute mean and variance**

$$
\bar d_i = \Sigma_{j=1}^{n_i} \frac{d_{ij}}{n_i}
$$
$$
\bar d = \Sigma^{n}_{i=1} \frac{d_i}{n}
$$

$$
s_i^2 = \Sigma_{j=1}^{n_i} \frac{(d_{ij} - \bar d_i)^2}{n_i-1}
$$
**Step 2: Compute pooled estimate of within subject error**

$$
s_{dw}^2 = \Sigma_{i=1}^{n} [\frac{n_i-1}{N-n} \cdot s_i^2]
$$

**Step 3: Compute pooled estimate of between subject error**

$$
s^2_b = \Sigma_{i=1}^n \frac{ (\bar d_i - \bar d)^2}{n-1}
$$

**Step 4: Compute the harmonic mean of the replicate size**

$$
m_h = \frac{n}{\Sigma_{i=1}^n m_i^{-1}}
$$

**Step 5: Compute SD of the difference **

$$
s_d^2 = s^2_b + (1+m_h^{-1}) \cdot s_{dw}^2
$$
**Step 6: Calculate l and u**

$$
l = s_d^2 - \sqrt{[s_d^2 \cdot (1 - \frac{n-1}{\chi^2_{(1-\alpha, n-1)}})]^2+[(1-m_h^{-1}) \cdot (1- \frac{N-n}{\chi^2_{(1-\alpha, N-n)}})]^2}
$$
$$
u = s_d^2 + \sqrt{[s_d^2 \cdot (1 - \frac{n-1}{\chi^2_{(1-\alpha, n-1)}})]^2+[(1-m_h^{-1}) \cdot (1- \frac{N-n}{\chi^2_{(1-\alpha, N-n)}})]^2}
$$
**Step 7: Compute LME and RME**

$$
LME = \sqrt{\frac{z_{\alpha} \cdot s_d^2}{n} + z_{\beta/2}^2 \cdot (\sqrt{u}-\sqrt{s^2_d} )^2}
$$

$$
RME = \sqrt{\frac{z_{\alpha} \cdot s_d^2}{n} + z_{\beta/2}^2 \cdot (\sqrt{l}-\sqrt{s^2_d} )^2}
$$


### LoA

$$
LoA_{lower} = \bar d - z_{\beta/2} \cdot s_d
$$


$$
LoA_{upper} = \bar d + z_{\beta/2} \cdot s_d
$$

### Lower LoA CI

$$
Lower \space CI = LoA_{lower} - LME
$$


$$
Upper \space CI = LoA_{lower} + RME
$$

### Upper LoA CI

$$
Lower \space CI = LoA_{upper} - RME
$$


$$
Upper \space CI = LoA_{upper} + LME
$$

# Checking Assumptions

The assumptions of normality, heteroscedasticity, and proportional bias can all be checked using the `check` method.

The function will provide 3 plots: Q-Q normality plot, standardized residuals plot, and residuals plot.

All 3 plots will have a statistical test in the bottom right corner. The Shapiro-Wilk test is included for the normality plot, the Bagan-Preusch test for heterogeneity, and the test for linear slope on the residuals plot. Please note that there is no formal test of proportional bias for the tolerance limits, but a plot is still included for visual checks.

## An Example

```{r}
a1 = agree_test(x = reps$x,
                y = reps$y,
                agree.level = .8)

check(a1)
```


# Proportional Bias

As the check plots for `a1` show, proportional bias can sometimes occur. In these cases @bland1999 recommended adjusting the bias and LoA for the proportional bias. This is simply done by include a slope for the average of both measurements (i.e, using an intercept + slope model rather than intercept only model).

For any of the "agree" functions, this can be accomplished with the `prop_bias` argument. When this is set to TRUE, then the proportional bias adjusted model is utilized. However, you should be careful with interpreting the hypothesis tests in these cases because the results are likely bogus for the extreme ends of the measurement. In any case, plots of the data should always be inspected

```{r}
a1 = agree_test(x = reps$x,
                y = reps$y,
                prop_bias = TRUE,
                agree.level = .8)
print(a1)

plot(a1)
```


# "Big" Data

Sometimes there may be a lot of data and individual points of data on Bland-Altman plot may be less than ideal. In order to change the plots from showing the individual data points we can modify the `geom_point` argument.

```{r}
set.seed(81346)
x = rnorm(750, 100, 10)
diff = rnorm(750, 0, 1)
y = x + diff

df = data.frame(x = x,
                y = y)

a1 = agreement_limit(data = df,
                     x = "x",
                     y = "y",
                     agree.level = .95)

plot(a1,
     geom = "geom_point")

plot(a1,
     geom = "geom_bin2d")

plot(a1,
     geom = "geom_density_2d")

plot(a1,
     geom = "geom_density_2d_filled")

plot(a1,
     geom = "stat_density_2d")
```


# References
