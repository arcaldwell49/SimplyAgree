---
title: "Reliability Analysis"
author: "Aaron R. Caldwell"
date: "Last Updated: `r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 2
bibliography: refs.bib
link-citations: true
vignette: >
  %\VignetteIndexEntry{Reliability Analysis}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(SimplyAgree)
```

# Background

Another feature of this R package is the ability to estimate the reliability of a measurement. This R package allows for the calculation of Intraclass Correlation Coefficients (ICC), various standard errors (SEM, SEE, and SEP), and coefficient of variation. All of the underlying calculations (sans the coefficient of variation) is based on the paper by @weir2005^[The paper by Weir also appears to heavily rely on the work of @shrout1979 and @mcgraw1996]. This is a fairly popular paper within my own field (kinesiology), and hence was the inspiration for creating this function that provides all the calculative approaches included within that manuscript.

# Code Demonstration

For this package, the test-retest reliability statistics can be calculated with the `reli_stats` function. This function allow for data to be input in a long (multiple rows of data for each subject) or in wide (one row for each subject but a column for each item/measure).

For the long data form, the column containing the subject identifier (`id`), item number (`item`), and measurements (`measure`) are provided. In this function I refer to items similar to if we were measuring internal consistency for a questionnaire (which is just a special case of test-retest reliability). So, `item` could also be refer to time points, which is what is typically seen in human performance settings where test-retest reliability may be evaluated over the course of repeated visits to the same laboratory. If `wide` is set to `TRUE` then the columns containing the measurements are provided (e.g., `c("value1","value2","value3")`).

To demonstrate the function, I will create a data set in the wide format.

```{r}

  # Example from Shrout and Fleiss (1979), pg. 423
  dat = data.frame(judge1 = 
                     c(9,6,8,7,10,6),
                   judge2 = 
                     c(2,1,4,1,5,2),
                   judge3 = 
                     c(5,3,6,2,6,4),
                   judge4 = 
                     c(8,2,8,6,9,7))
```


Now, that we have a data set (`dat`), I can use it in the `reli_stats` function.

```{r}
test1 = reli_stats(
  data = dat,
  wide = TRUE,
  col.names = c("judge1", "judge2", "judge3", "judge4")
)
```

This function also has generic print and plot functions. The output from print provides the coefficient of variation, standard errors, and a table of various intraclass correlation coefficients. Notice the conclusions about the reliability of the measurement here would vary greatly based on the statistic being reported. What statistic you should report is beyond the current vignette, but is heavily detailed in @weir2005. However, within the table there are columns for `model` and `measures` which describe the model that is being used and the what these different ICCs are intended to measure, respectively.

```{r}
print(test1)
```

Also included in the results is a plot of the measurements across the items (e.g., time points).

```{r, fig.width=6, fig.height=6}
plot(test1)
```

## Confidence Intervals

TBA

# Calculative Approach

## Model

The linear mixed model used for the calculations is specified as the following:

$$
\begin{aligned}
  \operatorname{Y}_{i}  &\sim N \left(\alpha_{j[i],k[i]}, \sigma^2 \right) \\
    \alpha_{j}  &\sim N \left(\mu_{\alpha_{j}}, \sigma^2_{\alpha_{j}} \right)
    \text{, for id j = 1,} \dots \text{,J} \\
    \alpha_{k}  &\sim N \left(\mu_{\alpha_{k}}, \sigma^2_{\alpha_{k}} \right)
    \text{, for items k = 1,} \dots \text{,K}
\end{aligned}
$$

## Components of Variance

**Mean Squared Error (MSE)**

$$
MSE = \sigma^2
$$

**Variance Between Subjects**

$$
MSB = n_k \cdot \sigma^2_{\alpha j} + \sigma^2
$$

**Variance Between Items/Judges**

$$
MSJ = n_{j} \cdot \sigma^2_{\alpha_{k}} + \sigma^2
$$

**Variance Within Subjects/Participants**

$$
MSW = \sigma^2 + \sigma^2_{\alpha_{k}}
$$


## Intraclass Correlation Coefficients

$$
\begin{aligned}
ICC_{(1,1)} = \frac{MSB - MSW}{MSB + (n_j-1) \cdot MSW} \\
ICC_{(2,1)} = \frac{MSB - MSE}{MSB+(n_j -1) \cdot MSE + n_j \cdot (MSJ - MSE) \cdot n^{-1}} \\
ICC(_{3,1)} = \frac{MSB - MSE}{MSB + (n_j -1) \cdot MSE}
\\
\\
ICC_{(1,k)} = \frac{MSB - MSW}{MSB}
\\
ICC_{(2,k)} = \frac{MSB - MSW}{MSB + (MSJ - MSE) \cdot n_j^{-1}}
\\
ICC_{(3,k)} = \frac{MSB - MSE}{MSB}
\end{aligned}
$$
## ICC Confidence Intervals

TBA

## Standard Error Calculations

The standard error of the measurement (SEM), standard error of the estimate (SEE), and standard error of prediction (SEP) are all estimated with the following calculations.


$$
\begin{aligned}
 SEM = \sqrt{MSE} \\
\\

 SEE = \sqrt{\frac{\sigma^2+\sigma^2_{\alpha j}+\sigma^2_{\alpha k}}{(n_j-1)}} \cdot \sqrt{ICC_{(3,1)} \cdot (1-ICC_{(3,1)})} \\ 
 \\
 SEP = \sqrt{\frac{\sigma^2+\sigma^2_{\alpha j}+\sigma^2_{\alpha k}}{(n_j-1)}} \cdot \sqrt{1-ICC_{(3,1)}^2} \\
  
\end{aligned}
$$
## Coefficient of Variation 

The CV is calculated 3 potential ways within `reli_stats`. I highly recommend reporting the default version of CV.

1. From the MSE (default)

$$
CV = \frac{MSE }{ \bar y}
$$

2. From the SEM (most conservative)^[Also called "%SEM" in some texts]

$$
CV = \frac{SEM}{ \bar y}
$$

3. From the model residuals (most liberal)

$$
CV = \frac{\sqrt{\frac{\Sigma^{N}_{i=1}(y_i - \hat y_i)^2}{N_{obs}}}}{ \bar y}
$$
## Other Confidence Intervals

TBA

# References
